---
title: "HW4"
author: "Zachary Palmore"
date: "4/17/2021"
output: pdf_document
subtitle: "Business Analytics and Data Mining"
header-includes: 
- \newcommand{\bcenter}{\begin{center}}
- \newcommand{\ecenter}{\end{center}}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

\bcenter

# Assignment 4

\ecenter

___

```{r warning=F, message=F}
# Packages
library(tidyverse)
library(kableExtra)
library(ggcorrplot)
library(reshape2)
library(bestNormalize)
library(caret)
library(MASS)
library(pROC)
library(stats)
library(ROCR)
theme_set(theme_minimal())
```

\newpage

## Purpose 

In this homework assignment, we will explore, analyze and model a data set containing approximately 8000 records representing a customer at an auto insurance company. Each record has two response variables. The first response variable, TARGET_FLAG, is a 1 or a 0. A “1” means that the person was in a car crash. A zero means that the person was not in a car crash. The second response variable is TARGET_AMT. This value is zero if the person did not crash their car. But if they did crash their car, this number will be a value greater than zero.

Our objective is to build multiple linear regression and binary logistic regression models on the training data to predict the probability that a person will crash their car and also the amount of money it will cost if the person does crash their car. We can only use the variables given (or variables derived from the variables provided). Below is a short description of the variables of interest in the data set:



```{r}
# short descriptions of variables as table from matrix
vardesc <- data.frame(matrix(c(
'INDEX',	'Identification variable',
'TARGET_FLAG',	'Was car in a crash? 1 = Yes, 0 = No',
'TARGET_AMT',	'Cost of car crash',
'AGE',	'Age of driver',
'BLUEBOOK',	'Value of vehicle',
'CAR_AGE',	'Vehicle age',
'CAR_TYPE',	'Type of car',
'CAR_USE', 'Main purpose the vehicle is used for',
'CLM_FREQ',	'Number of claims filed in past five years',
'EDUCATION',	'Maximum education level',
'HOMEKIDS',	'Number of children at home',
'HOME_VAL',	'Value of driver\'s home',
'INCOME',	'Annual income of the driver',
'JOB',	'Type of job by standard collar categories',
'KIDSDRIV',	'Number of children who drive',
'MSTATUS',	'Marital status',
'MVR_PTS',	'Motor vehicle inspection points',
'OLDCLAIM',	'Total claims payout in past five years',
'PARENT1',	'Single parent status',
'RED_CAR',	'1 if car is red, 0 if not',
'REVOKED',	'License revoked in past 7 years status',
'SEX',	'Driver gender',
'TIF',	'Time in force',
'TRAVETIME',	'Distance to work in minutes',
'URBANICITY',	'Category of how urban the area the driver lives is',
'YOJ', 'Number of years on the job'
),  byrow = TRUE, ncol = 2))
colnames(vardesc) <- c('Variable', 'Description')
kbl(vardesc, booktabs = T, caption = "Variable Descriptions") %>%
  kable_styling(latex_options = c("striped", "HOLD_position"), full_width = F)
```







___


\newpage


## Introduction

There are 8161 observations of 26 variables in this data set. Each variable is a statistic describing the behavior of an individual driver. Presumably, they are connected to the presence or absence of an accident and contain enough information to estimate the cost of a claim for the accident. To begin, we read in two data sets, one for model training appropriately named, 'tdata,' and one for evaluation named 'edata.' 


```{r}
tdata <- read.csv(
  "https://raw.githubusercontent.com/palmorezm/msds/main/621/HW4/insurance_training_data.csv")
edata <- read.csv(
  "https://raw.githubusercontent.com/palmorezm/msds/main/621/HW4/insurance-evaluation-data.csv")
```



We capture the first four initial observations of driver behavior. In this case, we are looking for any immediate or glaring problems with the first few rows. For example, we check that the data type matches the intended variable, that the observation makes logical sense for its intended column header, and that the data is organized appropriately into rows and columns among other big picture things. Those observations are displayed in table 2 titled "Initial Observations."



```{r}
initialobs <- tdata[1:4,]
kbl(t(initialobs), booktabs = T, caption = "Initial Observations") %>%
  kable_styling(latex_options = c("striped", "HOLD_position"), full_width = F) %>%
  add_header_above(c(" ", " ", "Row Number", " ", " ")) %>%
  footnote(c("Includes the first four observations of all variables in the data"))
```


As a positive, each row does seem to contain the proper corresponding variable. There is no blatant mixing. However, there are noticeable issues. The variables 'INCOME' and 'HOME_VAL' contain '\$' character symbols which are completely irrelevant and will cause major problems if we were to interpret or analyze with the data as is. Interestingly, there is also a 'z_' present in some categories and not in others. To understand how these variables may affect the analysis as is and to learn exactly what must be done to prepare the data, we must explore further. 




___



\newpage



## Data Exploration

Before we delve into the nitty gritty of this data set, we should consider what effect each of these variables might exert on the outcome. Since there are two targets of different types, and thus two models (one binary logistic classifier and one multiple linear regression) there could be an influence on either or both models. As we understand it, the theoretical effects of each variable are recorded in the table below.

```{r}
# theoretical effects
vareffects <- data.frame(matrix(c(
'INDEX',	'None',
'TARGET_FLAG',	'None',
'TARGET_AMT',	'None',
'AGE',	'Youngest and Oldest may have higher risk of accident',
'BLUEBOOK',	'Unknown on probability of collision but correlated with payout',
'CAR_AGE',	'Unknown on probability of collision but correlated with payout',
'CAR_TYPE',	'Unknown on probability of collision but correlated with payout',
'CAR_USE', 'Commerical vehicles might increase risk of accident',
'CLM_FREQ',	'Higher claim frequency increases likelihood of future claims',
'EDUCATION',	'Theoretically higher education levels lower risk',
'HOMEKIDS',	'Unknown',
'HOME_VAL',	'Theoretically home owners reduce risk due to more responsible driving',
'INCOME',	'Theoretically wealthier drivers have fewer accidents',
'JOB',	'Theoretically white collar+ jobs are safer',
'KIDSDRIV',	'Increased risk of accident from inexperienced driver',
'MSTATUS',	'Theoretically married people drive safer',
'MVR_PTS',	'Increased risk of accident',
'OLDCLAIM',	'Increased risk of higher payout with previous payout',
'PARENT1',	'Unknown',
'RED_CAR',	'Theoretically increased risk of accident based on urban legend',
'REVOKED',	'Increased risk of accident if revoked',
'SEX',	'Theoretically increased risk of accident for women based on urban legend',
'TIF',	'Decreased risk for those who have greater loyalty',
'TRAVETIME',	'Longer distances increase risk of accident',
'URBANICITY',	'The more urban the area the greater the risk of accident',
'YOJ', 'Decreased risk for those with greater longevity'
),  byrow = TRUE, ncol = 2))
colnames(vareffects) <- c('Variable', 'Effect')
kbl(vareffects, booktabs = T, caption = "Theoretical Variable Effects") %>%
  kable_styling(latex_options = c("striped", "HOLD_position"), full_width = F)
```



This table considers the effects of both models but they are only theoretical and may not necessarily reflect the true influence. We will evaluate these directly in the model selection process. For now, they will serve as general baseline expectations for exploration and preparation. We continue by exploring the data to determine where munging may be necessary. 

Unfortunately, this data needs work even before we are able to make visualizations and contemplate improvements to the model. We consider the amount of missing values in relative proportions to each variable, followed by their respective data types, an example observation of each type, and the quantity of unique factors to each variable. We already know that some major work needs to be done in readjusting data types but we do not know the extent to which each variable needs improvement. This will help narrow down what is needed to prepare the data for modeling. Results are shown in the table:



```{r}
tdata.nas <- lapply(tdata, function(x) sum(is.na(x)))
tdata.len <- lapply(tdata, function(x) length(x))
tdata.permis <- lapply(tdata, function(x) round(sum(is.na(x))/length(x)*100, 1))
tdata.types <- lapply(tdata, function(x) class(x))
tdata.firstob <- lapply(tdata, function(x) head(x, 1))
tdata.uniques <- lapply(tdata, function(x) length(unique(factor(x))))
tdata.tbl.natypes <- cbind(tdata.nas, tdata.len, tdata.permis, tdata.types, tdata.firstob, tdata.uniques) 
colnames(tdata.tbl.natypes) <- c("Missing", "Total", "%", "Data Type", "Example", "Factors")
kbl(tdata.tbl.natypes, booktabs = T, caption = "Data Characteristics") %>%
  kable_styling(latex_options = c("striped", "HOLD_position"), full_width = F)
```



Three variables contain incomplete records including ‘AGE’, ‘YOJ’,  and ‘CAR_AGE’ with 0.1%, 5.6%, and 6.2% of their data missing respectively. Theoretically each variable would have 8161 total observations as noted in the table. The data types are either integer or numeric and the examples display what the type looks like for easy referencing. A calculation of the unique factors for each variable is included to gauge whether converting to a factor data type would be right for the variable and count the number of unique values to each. These are major concerns. 

Minima, quartiles, averages, and maximums were computed to compare the numeric integer variables. Although the order of the variables remains the same as in the previous table, we added a missing values column with the row identifier ‘NA’ to count the number missing for tracking purposes. We put this together in a table called Summary Characteristics. Of course, several of the variables will need to be altered before we can evaluate if the data makes sense in a real-life scenario. These are shown as NA in the table. 



```{r}
tdata.summary.tbl <- summary(tdata)
kbl(t(tdata.summary.tbl), booktabs = T, caption = "Summary Characteristics") %>%
  kable_styling(latex_options = c("striped", "scale_down", "hold_position"), full_width = F)
```

Notice, there are quite a few NA values and our binary outcomes such as 'KIDSDRIV',and even our 'TARGET_FLAG' appear to be skewed heavily. It will require a closer at their distributions look to be sure of this but regardless, they will need to be dealt with if we plan to use them in our models. Factors like the single parent indicator, 'PARENT1', the individuals binary gender 'SEX', whether a driver's license was revoked 'REVOKED' and others like 'MSTATUS,''URBANICITY,' and 'CAR_USE,' take on a character data types that are not useful in modeling. For practical purposes, they should be made factors so that their categories may be understood fully.  

Several of these variables also have statistics that do not make logical sense. For example, 'CAR_AGE' has a minimum value of -3. This is not possible. Other numeric variables are clearly sets of dollar values but show as character strings. These will need to converted to numeric data types and the quantitative value portion of the string extracted. This and the factorization of cateogircal variables without  a necessary order should help eliminate the many missing or 'NA' calculations performed above. 

Generally, it is best to avoid reviewing the distribution of variables prior to munging the full data set to visualize all variables simultaneously.However, we have enough variables that are already of the numeric type that plotting them each together might overcrowd the chart. A new strategy should be considered. In this effort, we review the density of the numeric variables as they exist now to evaluate agreement with the assumptions of linearity. 


```{r}
tdata %>% 
  select_if(is.numeric) %>% 
  gather %>% 
  ggplot() +
  facet_wrap(~ key, scales = "free") +
  geom_density(aes(value, color = value, fill = key, alpha = .5)) + theme(axis.title = element_blank(), legend.position = "none") + ggtitle("Numeric Variable Density") + theme(plot.title = element_text(hjust = 0.5))
```


Variables 'CLM_FREQ,' 'HOMEKIDS,' and 'KIDSDRIV' show integer values for a discrete distribution. These will be treated differently in the preparation process because their non-conformity with a linearity will not effect their ability to predict in the binary logistic classification model. Results in that model to examine the probability of 'TARGET_FLAG' will remain stable. However, the multiple linear regression model suffers a loss of potential predictors due to their inability to meet the assumptions of linear regression. 


Our continuous variables, 'AGE,' 'CAR_AGE,' 'TRAVTIME,' 'MVR_PTS,' and 'YOJ' are much better suited to predict 'TARGET_AMT.' To our benefit, age is normally distributed with the bulk of the driver ages' falling between 30 and 60. Given the theoretical effect of younger drivers on the likelihood of an accident this variable could be useful in our logistic regression model especially when converted to a binary outcome of young or not. But there are now reasons to doubt their agreement with the assumptions. 

Consider the assumption of normality where only the 'AGE' variable satisfies. All other non-discrete and non-integer values, including 'CAR_AGE,' 'YOJ,' 'MVR_PTS,' 'TIF,' and 'TRAVTIME' are poorly classified as normal, if at all. There are at least two distinct peaks in the distribution of 'YOJ,' 'TIF,' and 'CAR_AGE.' Our 'MVR_PTS' is too dense at the front of the distribution but still manages to have less skewness than our 'TARGET_AMT.' The variable closest to satisfying this assumption is perhaps 'TRAVTIME' which has an unproven theoretical effect to increase the chance of an accident as the time increases and may also be bimodal. 

Given the problematic nature of a major assumption of linear regression it would be tough to say modeling with any of these could make useful predictions. Without intense transformations we risk guessing wildly at the resultant amount. However, the degree to which transformations must be performed to cause this data to appear normal would grossly misrepresent the data and greatly increase our error rate in both models if we chose to use assign them places in each. However, we must continue knowing this and attempt to improve upon the expectation. In this endevaour, we also check a few other assumptions with violin plots and a boxplot estimation. 

```{r}
tdata %>% 
  select_if(is.numeric) %>% 
  gather %>% 
  ggplot(aes(value, key)) +
  facet_wrap(~ key, scales = "free") +
  geom_violin(aes(color = key, alpha = 1)) + 
  geom_boxplot(aes(fill = key, alpha = .5), notch = TRUE, size = .1, lty = 3) +  
  stat_summary(fun.y = mean, geom = "point",
               shape = 8, size = 1.5, color = "#000000") + 
  theme(axis.text = element_blank(), 
        axis.title = element_blank(), 
        legend.position = "none") + 
  ggtitle("Numeric Variable KDE & Distribution") + 
  theme(plot.title = element_text(hjust = 0.5)) 
```


While the good news is our discrete integer values (that will be partially reorganized into unordered factors) continue to give us hope that model accuracy will be reasonable for our binary model, the existence of numerous outliers, high levels of variation in some distributions, and little to no normality, reduce the ability of our multiple linear regression model to produce accurate results. In this visual we can clearly note the presence of outliers for our 'TARGET_AMT' variable. Unfortunately, it appears nearly all of our useful data (where the amount is greater than zero) are considered outliers. A selection of all values greater than zero might be useful but it eliminates the option of the multiple linear regression model to predict a value of zero when there is no claim made. This is an interesting conundrum and one we should consider of the utmost importance when preparing the data and building models. 


While some other numeric variables appear to confirm our density plots, others show new issues. The normally distributed 'AGE' variable contains many outliers above and below its distribution with a slightly larger number of older drivers stretching the distribution upwards. The outliers for our discrete integer values shown as black dots would be much better suited to a bar chart. This might also let any other variables that exhibit a discrete pattern with categorical values show through a bit better. 


```{r}
tdata %>% 
  select_if(is.integer) %>%
  gather() %>% 
  filter(value == 0 | 1) %>% 
  group_by(key) %>% 
  ggplot() +
  facet_wrap(~ key, scales = "free") +
  geom_bar(aes(value, color = value, fill = key, alpha = .5)) + theme(axis.title = element_blank(), legend.position = "none") + ggtitle("Integer Frequencies") + theme(plot.title = element_text(hjust = 0.5))
```


Outliers contained in the 'TRAVTIME' variable in the violin plot were mainly commute times of the 'greater than' kind. However, in this we notice there are more drivers with a zero minute commute time than at the average of all commuters. A similar spike in the years on job or 'YOJ' variable indicates that there are just as many drivers with near zero year on the job as there are drivers with 10 years on the job. We select a few of these to take a closer look at their categories and how they fall into equally weighted bars. 



```{r}
tdata %>% 
  dplyr::select(TARGET_FLAG, MVR_PTS, CLM_FREQ, HOMEKIDS, KIDSDRIV, TIF) %>% 
  gather() %>% 
  ggplot(aes(value)) +
  facet_wrap(~ key, scales = "free") + 
  geom_bar(aes(value, color = key, fill = key, alpha = .5)) + theme(axis.title = element_blank(), legend.position = "none") + ggtitle("Select Integer Frequencies") + theme(plot.title = element_text(hjust = 0.5))
```

The quantity of drivers who do not have kids that drive is much larger than any driver that has kids. The same applies to the number of kids at home and the claim frequencies. The magnitude of difference in these categories is severe and may cause issues when trying to predict the probability of an accident. If the claim frequency is majority zero, along with the number of kids at home and almost every other variable follows the same pattern, then predicting the minority class becomes more difficult. We should expect a noise-filled model with faint signal. This issue in the binary logistic classifier makes it even worse for the multiple linear regression model. 

Building on these insights, this infant minority class must be focused on to improve the accuracy and precision of both model types. Some might consider it productive to oversample the minority class, however, if we cannot reasonably assume the majority class fits the assumptions of linear regression nor that either case is particularly well-cleaned (transformed, prepared, and error-controled) enough to base real predictions on than the purpose of oversampling is moot. Otherwise, we would be trying to build a model off of incorrect assumptions and inevitably come to the wrong conclusions. Not to mention, these conclusions would be far from the reality on which the data is supposed to be representative. 

To get a better sense of where these data may overlap and the strength of their relationships we consider the correlations of the numeric variables. This includes the discrete integer values with categories and the continuous numeric variables that have not undergone data type changes. There is less of a need to consider the other non-numeric variables at this time since the binary logistic classification model does not rely on the same rules as multiple linear regression to interpret the data.


```{r}
tdata %>%
  select_if(is.numeric) %>% 
  cor() %>% 
  ggcorrplot(method = "circle", type="upper", 
             ggtheme = ggplot2::theme_minimal, legend.title = "Influence") + coord_flip() 
```


Again, since this is prior to the data preparation stage, we include the index of each observation. This is a good base indicator of variables with little to no correlation with our target variables 'TARGET_FLAG' and 'TARGET_AMT.' The directional vector of the influence in each variable is color coded from -1 to 1 with the most positive correlations being closest to 1. The size of each circle represents the strength in magnitude of the relationship between the variables. 

Of course, our two target variables, 'TARGET_FLAG' and 'TARGET_AMT' are quite strongly positively correlated. The same applies for the variables 'KIDSDRIV' and 'HOMEKIDS' given that one driver should not be able to have a kid driving without having at least one kid at home. These stronger correlations pass the sanity check. 

Alternatively, the weaker, but perhaps more interesting variables, include mostly positive correlations. It seems it is much easier to increase your chances of an accident than it is to reduce them. Our only negatively correlated (blue) relationship comes from 'TIF' and our targets. Looking at this variable with 'TARGET_FLAG' you can reduce your chance of getting into an accident increasing the time you spend at the same insurance company. This is likely a result of people who stick around because they have not had an accident and their rate has remained steady. Otherwise, the driver would probably search for new insurance. 

These correlations elucidate the relationship of our 'TARGET_FLAG' or the chance of an accident better than the relationship of the variables with the 'TARGET_AMT.' Keep in mind that all of these variables are numeric types that could be used model with multiple linear regression. They are not going to be, since several of them are categorical factors and not continuous distributions, but recall that all but one fails at least one assumption of linear regression. As mentioned, the accuracy of this linear regression model will be affected by these poorly correlated data. 








___



\newpage



## Data Preparation

This section will implement the changes necessary to build models with the data. Since we have two model types, we must separate the data into groups. One group will have data specialized for the binary logistic classification model and the other for the multiple linear regression. We have already determined that we will have a limited pool of data to model with for the multiple linear regression. With that said, we still attempt to scrape together some resemblance of a realistic linear regression model ignoring the fact that the data is not in accordance with the assumptions of linear regression.


To begin, we extract the numeric variables present in 'INCOME,' 'HOME_VAL,' and others like it. In doing so we drop the '\$' sign but retain the value. Then we impute the median value for those that had missing values and evaluate the changes with summary statistics. These are recorded and calculated separately. Once the differences are checked to ensure that the variables are not drastically far off from the original values we recombine them with the training data. This process is shown below along with the first table of summary statistics from the numeric imputed variables. 

```{r}
# Select character variables
chars <- tdata %>% 
  dplyr::select_if(is.character)
# Use function to extract dollars
to_num <- function(x){
  x <- as.character(x)
  x <- gsub(",", "", x)
  x <- gsub("\\$", "", x)
  as.numeric(x)
}
# Specify those dollar variables 
income.values <- to_num(chars$INCOME)
home.values <- to_num(chars$HOME_VAL)
bluebook.values <- to_num(chars$BLUEBOOK)
oldclaim.values <- to_num(chars$OLDCLAIM)
concept_df <- as.data.frame(cbind(income.values, 
                    home.values, 
                    bluebook.values, 
                    oldclaim.values))
income.values.stat <- to_num(chars$INCOME)
home.values.stat <- to_num(chars$HOME_VAL)
bluebook.values.stat <- to_num(chars$BLUEBOOK)
oldclaim.values.stat <- to_num(chars$OLDCLAIM)
# impute median values for missing variables
income.values[is.na(income.values)] <- 
  median(income.values, na.rm = TRUE)
home.values[is.na(home.values)] <- 
  median(home.values, na.rm = TRUE)
bluebook.values[is.na(bluebook.values)] <- 
  median(bluebook.values, na.rm = TRUE)
oldclaim.values[is.na(oldclaim.values)] <- 
  median(oldclaim.values, na.rm = TRUE)
# Recombine into data frame
dollar.values <- 
  data.frame(cbind(income.values, 
                   home.values, 
                   bluebook.values, 
                   oldclaim.values))
dollar.values.stats <- 
  data.frame(cbind(income.values.stat, 
                   home.values.stat, 
                   bluebook.values.stat,
                   oldclaim.values.stat))
# Join with training data
tdata <- data.frame(cbind(tdata, dollar.values))
# Check the difference
dollar.values.tbl <- summary(dollar.values)
dollar.values.stats.tbl <- summary(dollar.values.stats)
kbl(dollar.values.tbl, booktabs = T, caption = "Imputed Summary Statistics") %>%
kable_styling(latex_options = c("striped", "hold_position"), full_width = F)
```

We compare this to the second table and observe the changes. If the differences between these is small, we can add the imputed variables to our original training data rather than eliminating the rows with missing variables altogether. The second table is shown here:

```{r}
kbl(dollar.values.stats.tbl, booktabs = T, caption = "Original Summary Statistics") %>%
kable_styling(latex_options = c("striped", "hold_position"), full_width = F)
```

Since the differences between these variables is small and the values that were missing are no longer missing, we recombine the imputed data with the training data for later use. It turns out, it was reasonable to make these imputations, even though the data sets are skewed and do not contain total linearity or normality. 

Next, we convert the categorical variables to factors rather than the integer or characters they were. Although the analysis will still interpret these factors as integers to perform computations, we will be able to recognize the various levels associated with each variable rather than a non-descriptive number. As a special note, we are going to interpret each of these factors as an unordered set. 

```{r}
# Covert categorical variables to factors 
factors <- tdata %>% 
  dplyr::select("PARENT1", 
         "MSTATUS", 
         "SEX", 
         "EDUCATION", 
         "JOB", 
         "CAR_USE",
         "CAR_TYPE",
         "RED_CAR", 
         "REVOKED", 
         "URBANICITY") 
factors <- data.frame(lapply(factors, function(x) as.factor(x)))
factors <- factors %>% 
  rename("parent1" = "PARENT1", 
         "mstatus" = "MSTATUS", 
         "sex" = "SEX", 
         "education" = "EDUCATION", 
         "job" = "JOB", 
         "car_use" = "CAR_USE", 
         "car_type" = "CAR_TYPE",
         "red_car" = "RED_CAR", 
         "revoked" = "REVOKED", 
         "urbanicity" = "URBANICITY")
tdata <- cbind(tdata, factors)
```

There was a highly unrealistic value for the variable 'CAR_AGE.' This should be excluded from the data set to avoid further damage to the modeling process. We simply find where the value is less than zero and set that value to NA. A summary of both is run to see how this changes the data. 


```{r}
# Exclude unrealistic values
tdata <- tdata %>% 
  mutate(car_age = ifelse(CAR_AGE<0, NA, CAR_AGE))
summary(tdata$car_age)
summary(tdata$CAR_AGE)
```


As we can see there was only one value in the 'CAR_AGE' variable that contained a negative number. For our purposes, we will consider the rest realistic. Another variable that we do not need as it provide not value to the model is the 'INDEX' variable. We remove this and other unnecessary variables from the training data by selecting the variables that we suspect we may need. The total number of variables present after this selection process is shown. 

```{r include=F}
full41 <- tdata
full41
full41[c(2:7, 15, 18, 22, 24, 27:41)]
```


```{r}
# Drop INDEX and other unnecessary columns
tdata <- tdata %>% 
  dplyr::select("TARGET_FLAG",
         "TARGET_AMT",
         "KIDSDRIV",
         "AGE",
         "HOMEKIDS",
         "YOJ",
         "TRAVTIME",
         "TIF",
         "CLM_FREQ",
         "MVR_PTS",
         "income.values", 
         "home.values",
         "bluebook.values",
         "oldclaim.values",
         "parent1", 
         "mstatus",
         "sex",
         "education",
         "job",
         "car_use",
         "car_age",
         "car_type",
         "red_car", 
         "revoked",
         "urbanicity")
# Check total variables present
length(colnames(tdata))
```

Because these variables still have missing values, further imputation is needed. The variables of 'AGE,' 'YOJ,' and 'CAR_AGE' are filled with the median value from each of their respective distributions. Of course, we created the missing value for 'CAR_AGE' but this one value does not effect the overall variable distribution but by 0.01% or about one in our total observations. This difference is negligible. 



```{r}
# More imputation
tdata$AGE[is.na(tdata$AGE)] <-
  median(tdata$AGE, na.rm = T)
tdata$YOJ[is.na(tdata$YOJ)] <-
  median(tdata$YOJ, na.rm = T)
tdata$car_age[is.na(tdata$car_age)] <- 
  median(tdata$car_age, na.rm = T)
sum(is.na(tdata))
```




```{r}
tdata %>% 
  dplyr::select(is.factor) %>%
  dplyr::select("car_type", "education", "job") %>% 
  gather() %>% 
  ggplot(aes(value)) + 
  facet_wrap(~ key, nrow = 3, scales = "free") + 
  geom_bar(aes(, fill = key )) + theme(axis.title = element_blank(), axis.text.x = element_blank(), legend.position = "none") + coord_flip() + ggtitle("Nonbinary Classifiers") + theme(plot.title = element_text(hjust = 0.5))
```


```{r}
tdata %>% 
  dplyr::select(is.factor) %>%
  dplyr::select("car_use", 
         "mstatus", 
         "parent1", 
         "red_car",
         "revoked",
         "sex",
         "urbanicity") %>% 
  gather() %>% 
  ggplot(aes(value)) + 
  facet_wrap(~ key, scales = "free") + 
  geom_bar(aes(, fill = key )) + theme(axis.title = element_blank(), axis.text.x = element_blank(), legend.position = "none") + coord_flip() + ggtitle("Binary Classifiers Counts") + theme(plot.title = element_text(hjust = 0.5))
```





```{r}
tdata %>% 
  select_if(is.numeric) %>%
  gather() %>% 
  ggplot(aes(key)) + 
  facet_wrap(~ key, scales = "free") + 
  geom_boxplot(aes(key, value, fill = key, alpha = .5)) + theme(axis.title = element_blank(), axis.text.x = element_blank(), legend.position = "none") + ggtitle("Numeric Distributions") + theme(plot.title = element_text(hjust = 0.5))
```


```{r}
# New features
tdata <- tdata %>% 
  mutate(city = ifelse(urbanicity == "Highly Urban/ Urban", 0, 1)) %>% 
  mutate(young = ifelse(AGE < 25, 1, 0)) %>% 
  mutate(clean_rec = ifelse(MVR_PTS == 0, 1, 0)) %>%
  mutate(previous_accident = ifelse(CLM_FREQ == 0 & oldclaim.values == 0, 0, 1)) %>% 
  mutate(educated = ifelse(education %in% c("Bachelors", "Masters", "PhD"), 1, 0)) %>% 
  mutate(avg_claim = ifelse(CLM_FREQ > 0, oldclaim.values/CLM_FREQ, 0))
```



```{r}
# Convert to factors 
tdata$city <- as.factor(tdata$city)
tdata$young <- as.factor(tdata$young)
tdata$clean_rec <- as.factor(tdata$clean_rec)
tdata$previous_accident <- as.factor(tdata$previous_accident)
tdata$educated <- as.factor(tdata$educated)
```



```{r}
tdata[26:31] %>% 
  select_if(is.factor) %>% 
  gather() %>% 
  ggplot(aes(value)) + 
  facet_wrap(~key, scales = "free") + 
  geom_bar(aes(fill = key, alpha = .5)) + theme(legend.position = "none", axis.title = element_blank()) + ggtitle("New Features") + theme(plot.title = element_text(hjust = 0.5))
```




```{r}
# Produce recommended transformations
bestNorms <- tdata[1:11,1:16]
df <- tdata %>% 
  select_if(is.numeric)
for (i in colnames(df)) {
  bestNorms[[i]] <- bestNormalize(df[[i]],
                                  allow_orderNorm = FALSE,
                                  out_of_sample =FALSE)
}
```


```{r}
# Continue focusing on realistic values
accident_costs <- tdata$TARGET_AMT[tdata$TARGET_AMT>.0]
```



```{r}
# Focus on selected variables 
bestNorms$target_amt$chosen_transform
tdata$target_amt <- scale(log(tdata$TARGET_AMT + 1))
tdata %>% 
  dplyr::select(where(is.numeric)) %>%
  gather %>% 
  ggplot() +
  facet_wrap(~ key, scales = "free") +
  geom_density(aes(value, color = value, fill = key, alpha = .5)) + theme(axis.title = element_blank(), legend.position = "none") + ggtitle("Numeric Variable Density") + theme(plot.title = element_text(hjust = 0.5))
```


```{r}
tdata %>% 
  dplyr::select(where(is.numeric)) %>%
  dplyr::select("TARGET_AMT","target_amt") %>%
  gather %>% 
  ggplot() +
  facet_wrap(~ key, scales = "free") +
  geom_density(aes(value, color = value, fill = key, alpha = .5)) + theme(axis.title = element_blank(), legend.position = "none") + ggtitle("Numeric Variable Density") + theme(plot.title = element_text(hjust = 0.5))
```



```{r}
# Split 70-30 training test
set.seed(1102)
tindex <- createDataPartition(tdata$TARGET_FLAG, p = .7, list = FALSE, times = 1)
train <- tdata[tindex,]
test <- tdata[-tindex,]
rindex <- tdata %>%
  filter(TARGET_FLAG == 1)
reg.tindex <- createDataPartition(rindex$TARGET_AMT, p = .7, list = FALSE, times = 1)
reg.train <- rindex[reg.tindex,]
reg.test <- rindex[-reg.tindex,]
```






___


\newpage


## Model Building

Using the training data set, build at least two different multiple linear regression models and three different binary 
logistic regression models, using different variables (or the same variables with different transformations). You 
may select the variables manually, use an approach such as Forward or Stepwise, use a different approach such 
as trees, or use a combination of techniques. Describe the techniques you used. If you manually selected a 
variable for inclusion into the model or exclusion into the model, indicate why this was done.

Discuss the coefficients in the models, do they make sense? For example, if a person has a lot of traffic tickets, 
you would reasonably expect that person to have more car crashes. If the coefficient is negative (suggesting that 
the person is a safer driver), then that needs to be discussed. Are you keeping the model even though it is counter 
intuitive? Why? The boss needs to know.


```{r}
model1 <- glm(TARGET_FLAG ~ previous_accident, 
              family = binomial(link = "logit"), train)
summary(model1)
```


```{r}
model2 <- glm(TARGET_FLAG ~ previous_accident + 
                city + young + clean_rec + 
                educated, family = binomial(link = "logit"), train)
summary(model2)
```


```{r}
model3 <- glm(TARGET_FLAG ~ previous_accident + 
                city + mstatus + income.values + 
                sex + car_use + educated + KIDSDRIV + 
                revoked, family = binomial(link = "logit"), 
              train)
summary(model3)
```


```{r}
model4 <- lm(target_amt ~ ., train) 
summary(model4)
```


```{r}
model5 <- lm(target_amt ~ income.values +
               home.values + bluebook.values + 
               oldclaim.values + avg_claim, 
             train) 
summary(model5)
```



```{r include=F, eval=F}
model7 <- lm(target_amt ~ 
               income.values + 
               home.values + 
               bluebook.values + 
               oldclaim.values + 
               # 2nd Degree
               ident(avg_claim, train^2) + 
               I(income.values^2) + 
               I(home.values^2) + 
               I(bluebook.values^2) + 
               I(oldclaim.values^2) + 
               I(avg_claim, train^2) + 
               # 3rd Degree
               I(avg_claim, train^3) + 
               I(income.values^3) + 
               I(home.values^3) + 
               I(bluebook.values^3) + 
               I(oldclaim.values^3) + 
               I(avg_claim, train^3), train
             ) 
pm <- stepAIC(model7, trace = F, direction = "both")
p <- summary(pm)$call
pm <- lm(p[2], df)
summary(pm)
```



```{r}
model6 <- lm(target_amt ~ . -TARGET_AMT -TARGET_FLAG, train) 
pm <- stepAIC(model6, trace = F, direction = "both")
summary(pm)
```



___


\newpage


## Model Selection

Decide on the criteria for selecting the best multiple linear regression model and the best binary logistic regression 
model. Will you select models with slightly worse performance if it makes more sense or is more parsimonious? 
Discuss why you selected your models. 
For the multiple linear regression model, will you use a metric such as Adjusted R2
, RMSE, etc.? Be sure to 
explain how you can make inferences from the model, discuss multi-collinearity issues (if any), and discuss other 
relevant model output. Using the training data set, evaluate the multiple linear regression model based on (a) 
mean squared error, (b) R2
, (c) F-statistic, and (d) residual plots. For the binary logistic regression model, will you 
use a metric such as log likelihood, AIC, ROC curve, etc.? Using the training data set, evaluate the binary logistic 
regression model based on (a) accuracy, (b) classification error rate, (c) precision, (d) sensitivity, (e) specificity, (f) 
F1 score, (g) AUC, and (h) confusion matrix. Make predictions using the evaluation data set.



```{r}
# Calculate predicted values
# Classifier Model
mod1.pred <- predict.glm(model1, test)
mod2.pred <- predict.glm(model2, test)
mod3.pred <- predict.glm(model3, test)
# Regression Model
mod4.pred <- predict(model4, test, interval = "prediction")
mod5.pred <- predict(model5, test, interval = "prediction")
mod6.pred <- predict(model6, test, interval = "prediction")
```



```{r}
modstat <- function(model, test, target = "TARGET_FLAG", threshold = 0.5){
  test$new <- ifelse(predict.glm(model, test, "response") >= threshold, 1, 0)
  cm <- confusionMatrix(factor(test$new), factor(test[[target]]), "1")
  df <- data.frame(obs = test$TARGET_FLAG, predicted = test$new, probs = predict(model, test))
  Pscores <- prediction(df$probs, df$obs)
  AUC <- performance(Pscores, measure = "auc")@y.values[[1]]
  pscores <- performance(Pscores, "tpr", "fpr")
  plot(pscores,main="ROC Curve", sub = paste0("AUC: ", round(AUC, 3)))
  results <- paste(cat("F1 = ", cm$byClass[7], " "), cm)
  return(results)
}
```




```{r}
modstat(model1, test)
```







```{r}
modstat(model2, test)
```



```{r}
modstat(model3, test)
```



```{r}
modstat(model4, test)
```



```{r}
modstat(model5, test)
```



```{r}
modstat(model6, test)
```



## Conclusion


