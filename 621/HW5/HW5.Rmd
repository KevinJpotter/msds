---
title: "HW5"
author: "Zachary Palmore"
date: "5/13/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Overview

In this homework assignment, you will explore, analyze and model a data set containing information on approximately 12,000 commercially available wines. The variables are mostly related to the chemical properties of 
the wine being sold. The response variable is the number of sample cases of wine that were purchased by wine distribution companies after sampling a wine. These cases would be used to provide tasting samples to restaurants and wine stores around the United States. The more sample cases purchased, the more likely is a wine to be sold at a high end restaurant. A large wine manufacturer is studying the data in order to predict the number of wine cases ordered based upon the wine characteristics. If the wine manufacturer can predict the number of cases, then that manufacturer will be able to adjust their wine offering to maximize sales.

Your objective is to build a count regression model to predict the number of cases of wine that will be sold given certain properties of the wine. HINT: Sometimes, the fact that a variable is missing is actually predictive of the target. You can only use the variables given to you (or variables that you derive from the variables provided).Below is a short description of the variables of interest in the data set:

## Introduction

```{r warning=F}
library(tidyverse)
library(psych)
library(kableExtra)
library(caret)
```




```{r}
tdata <- read.csv("https://raw.githubusercontent.com/palmorezm/msds/main/621/HW5/wine-training-data.csv")
edata <- read.csv("https://raw.githubusercontent.com/palmorezm/msds/main/621/HW5/wine-evaluation-data.csv")
```



```{r}
tdata[1:5,] %>% 
  t() %>%
  kbl(booktabs = T, caption = "Raw Data") %>%
  kable_styling(latex_options = c("striped", "HOLD_position"), full_width = F) %>%
  footnote(c("Includes the initial observations of all variables in the data"))
```




## Exploration

```{r}
tdata %>% 
  describe() %>%
  round(digits = 1) %>% 
  mutate(missing = 12975 - n) %>%
  select(n, missing, median, mean, sd, min, max, range, skew, se) %>% 
  kbl(booktabs = T, caption = "Raw Summary") %>%
  kable_styling(latex_options = c("striped", "HOLD_position", "scale_down"), full_width = F) %>%
  column_spec(1, width = "8em") %>%
  footnote(c("Missing variables calculated based on the assumption of 12795 observations for each"))
```







## Preparation



```{r}
# Consider realistic values and adjust accordingly
tdata <- abs(tdata)
tdata %>% 
  describe() %>%
  round(digits = 1) %>% 
  mutate(missing = 12975 - n) %>%
  select(n, missing, median, mean, sd, min, max, range, skew, se) %>% 
  kbl(booktabs = T, caption = "Updated Summary") %>%
  kable_styling(latex_options = c("striped", "HOLD_position", "scale_down"), full_width = F) %>%
  column_spec(1, width = "8em") %>%
  footnote(c("Minimum values were adjusted where applicable to describe the data realisticly"))
```



```{r}
# Impute missing values
tdata <- tdata %>%
  mutate(
  ResidualSugar = ifelse(is.na(ResidualSugar), median(ResidualSugar, na.rm = T), ResidualSugar),
  Chlorides = ifelse(is.na(Chlorides), median(Chlorides, na.rm = T), Chlorides),
  FreeSulfurDioxide = ifelse(is.na(FreeSulfurDioxide), median(FreeSulfurDioxide, na.rm = T), FreeSulfurDioxide),
  TotalSulfurDioxide = ifelse(is.na(TotalSulfurDioxide), median(TotalSulfurDioxide, na.rm = T), TotalSulfurDioxide),
  pH = ifelse(is.na(pH), median(pH, na.rm = T), pH),
  Sulphates = ifelse(is.na(Sulphates), median(Sulphates, na.rm = T), Sulphates),
  Alcohol = ifelse(is.na(Alcohol), median(Alcohol, na.rm = T), Alcohol),
  STARS_imputed = ifelse(is.na(STARS), 1, 0),
  STARS = ifelse(is.na(STARS), 1, STARS))
```


```{r}
set.seed(1225)
train_index <- createDataPartition(tdata$TARGET, p = .7, list = FALSE, times = 1)
train <- tdata[train_index,]
eval <- tdata[-train_index,]
```


```{r}
train[1:5,] %>% 
  t() %>%
  kbl(booktabs = T, caption = "Training Data") %>%
  kable_styling(latex_options = c("striped", "HOLD_position"), full_width = F) %>%
  footnote(c("Includes the initial observations of all variables in the data"))
```



```{r}
eval[1:5,] %>% 
  t() %>%
  kbl(booktabs = T, caption = "Evaluation Data") %>%
  kable_styling(latex_options = c("striped", "HOLD_position"), full_width = F) %>%
  footnote(c("Includes the initial observations of all variables in the data"))
```



```{r}
train %>% 
  describe() %>%
  round(digits = 1) %>% 
  mutate(missing = 8958 - n) %>%
  select(n, missing, median, mean, sd, min, max, range, skew, se) %>% 
  kbl(booktabs = T, caption = "Raw Summary") %>%
  kable_styling(latex_options = c("striped", "HOLD_position", "scale_down"), full_width = F) %>%
  column_spec(1, width = "8em") %>%
  footnote(c("Missing variables calculated based on the assumption of 8958 observations for each"))
```



```{r}
eval %>% 
  describe() %>%
  round(digits = 1) %>% 
  mutate(missing = 3837 - n) %>%
  select(n, missing, median, mean, sd, min, max, range, skew, se) %>% 
  kbl(booktabs = T, caption = "Raw Summary") %>%
  kable_styling(latex_options = c("striped", "HOLD_position", "scale_down"), full_width = F) %>%
  column_spec(1, width = "8em") %>%
  footnote(c("Missing variables calculated based on the assumption of 3837 observations for each"))
```


## Model Building

```{r}
model2 <- glm(TARGET ~ FixedAcidity + VolatileAcidity + Alcohol, family = quasipoisson, train)
summary(model2)
```



```{r}
train1 <- train %>%
  select(-LabelAppeal, -AcidIndex, -STARS, -STARS_imputed)
model2 <- glm(TARGET ~ ., family = quasipoisson, train1)
summary(model2)
```



```{r}
model3 <- glm(TARGET ~ LabelAppeal + STARS + AcidIndex + STARS_imputed, family = quasipoisson, train)
summary(model3)
```



## Model Selection 


```{r}
evaluate_model <- function(model, test_df, yhat = FALSE){
  temp <- data.frame(yhat=c(0:8), TARGET = c(0:8), n=c(0))
  
  if(yhat){
    test_df$yhat <- yhat
  } else {
    test_df$yhat <- round(predict.glm(model, newdata=test_df, type="response"), 0)
  }
  
  test_df <- test_df %>%
    group_by(yhat, TARGET) %>%
    tally() %>%
    mutate(accuracy = ifelse(yhat > TARGET, "Over", ifelse(yhat < TARGET, "Under", "Accurate"))) %>%
    mutate(cases_sold = ifelse(yhat > TARGET, TARGET, yhat) * n,
           glut = ifelse(yhat > TARGET, yhat - TARGET, 0) * n,
           missed_opportunity = ifelse(yhat < TARGET, TARGET - yhat, 0) * n) %>%
    mutate(net_cases_sold = cases_sold - glut,
           adj_net_cases_sold = cases_sold - glut - missed_opportunity)
  
  results <- test_df %>%
    group_by(accuracy) %>%
    summarise(n = sum(n)) %>%
    spread(accuracy, n)
  
  accurate <- results$Accurate
  over <- results$Over
  under <- results$Under
  
  cases_sold <- sum(test_df$cases_sold)
  net_cases_sold <- sum(test_df$net_cases_sold)
  adj_net_cases_sold <- sum(test_df$adj_net_cases_sold)
  missed_opportunity <- sum(test_df$missed_opportunity)
  glut <- sum(test_df$glut)
  
  confusion_matrix <- test_df %>%
    bind_rows(temp) %>%
    group_by(yhat, TARGET) %>%
    summarise(n = sum(n)) %>%
    spread(TARGET, n, fill = 0)
  
  return(list("confusion_matrix" = confusion_matrix, "results" = results, "df" = test_df, "accurate" = accurate, "over" = over, "under" = under, "cases_sold" = cases_sold, "net_cases_sold" = net_cases_sold, "adj_net_cases_sold" = adj_net_cases_sold, "glut" = glut, "missed_opportunity" = missed_opportunity))
}
```


```{r}
evaluate_model(model1, eval)
```


```{r}
evaluate_model(model2, eval)
```


```{r}
evaluate_model(model3, eval)
```



## Conclusion

When basing the assumption soley on how many cases are sold, it looks like model 3 is best. This model also has the greatest accuracy and was the best estimate of total cases for the business. If choosing a model based only the number of cases sold, this model should take priority.  









